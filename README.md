# kNN k-邻近算法分类器以及两个demo
机器学习
for python3
## 概述
kNN: k Nearest Neighbors

    Input:  inX: 矢量（样本矩阵、标签）与现有（测试、训练样本）数据集进行比较 (1xN)

            dataSet: m列已知向量的数据集 (NxM)
            
            labels: 数据集标签 (1xM 的矢量)
            
            k: 用于比较的邻居数量（应为奇数）
            
    Output: 最喜爱的类标签

  说到《机器学习实战》这本书时，我接触过的--所涉及AI知识面--程序员们，无疑对此书赞不决口。
  
  被誉为机器学习入门级神书！至今已经被再版28次，连西瓜书都不及它，足以证明其价值

  在学习和实践《机器学习实战》这本书时，发现有许多的地方没有与py俱进，耗费时间和精力去填坑，会极大的打击初学者的信心。

  譬如编译错误（头疼），测试，误差太大及其什么原因，怎么调参、优化和配置权重使得提高准确率和降低召回率。

  好了，模型调试完成后还要考虑其落地场景，在什么情况下使用这个模型达到效果最佳，同时数据前置条件要与后置条件是否能变得高效，以至于可以取代人力。
  
## kNN分类器的实现

  一个是kNN.py 原来的是用python2.7写的，自己想一遍原理再用python3.7.0写一遍，很有感觉了。

  一个是命令行输入kNN—main.py可以快速、简单尝试你想要结果。

  其中还有很多疑问留在代码里，以#Q 注释出来

## kNN分类其的实现

收集数据：
    1、将文本文件转换成字典即训练样本和类标签向量
    2、将图片转换为数组
    
## 对陌生异性好感度预测

调参：调试datingClassTest()中的hoRatio和变量k的值，使得错误率降低

## 手写识别系统

提高准确率的（即降低错误率的方式）：改变k值，随机选取训练样本，改变训练样本的数量
